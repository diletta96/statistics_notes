# Week 1 - INTRODUCTION TO DATA
##  What is statistics?
It's the subject that encompasses all aspects of learning from data. So, as a methodology, we're talking about the tools, the methods to allow us to work with data to understand that data.
A statistic is a numerical or graphical summary of a collection data (e.i. avarage score on final exam).
The FIELD of STATISTIC is an academic discipline focusing on reasearch methodology.
Data can be overwhelming --> making sanse of data usually involves reduction and summarization
REDUCTION= make dataset comprenhesible
SUMMARIZATION = depends primarily on goals of data cumsumer
Error = indicates the discripance from reality
Summarize data = often focusing on that typical or central value. But it's important to emphaseize on the variation of the data.

FORECASTING or PREDICTION (central task in statistics) --> efficient use of available data can make accuarte predictions about future

There are different accuarcy of the data.
HIGH ACCURACY i.e. age or height
MORE DIFFICULT i.e. blood pressure (varies minute to minute)
HARDER i.e. personality, mood

Statistic: major role in constructing and evaluating rigorous approaches for measuring difficul-to-define concepts and in assesing quality.


## What is data
Data can be :
- numbers
- images
- words
- audio

## Where do data come from
Two key types of data:

- organic/ process data --> generated by a computazied information system or extracted from from viedo or audio recordings. __The common point is that they're generated organically as the result of some process and they're often generated over time.__ e.i. Netflix viewing history or web browser activity or temperature/pollution sensors. Generate massive quantities of data = BIG DATA. The processing required significant computational resouces --> data scientists mine these data to study trends and uncover interesting relationship --> getting the data in a format that's suitable for analysis, that process alone requires very significant resources from a computational perspective. 

- Designed data collection -->  __Specific studies that are designed to specifically address a particular research objective.__  Individuals sampled from a population, interviewed about opitions on a particular topic (specifically designing a sample). Common feature:
    - sampling from populations, administratiion of carefully designed questions
    - typically datasets much smaller compared to organic/process dtaa sets
    - data colleted for a very specific reasons 

Important question: Are the data i.i.d.? __i.i.d.= indipendent and identically distributed data__. All the observations are independent of all the other observations and the values that we're looking at are all arising from some common statistical distribution, that's where the i.i.d terminology comes from. Given these i.i.d data, we can estimate the features of that distribution, things like the mean exam score, the variance in the exam scores, extreme percentiles of the exam scores and then make inference about those features.
If data are not i.i.d., need difefrent analytic procedures


Need to ask : __can we apply procedures that assume i.i.d. data?__ --> imporatant question before start analysis
Need to consider where the data come from --> organic processed data?

## Varible types
example :
BMI  would be reasonable to take the average of this variable.
__Quantitative Variables__ = numerical, measurable quantities in which arithmetic operations often make sense.  
Quantative viarables can be:
- CONTINUOS could take on any value within an interval, many possible values es time 
- DISCRETE = countable value, finite number of value es. numeber of children in a house

__Categorical (or Qualitative) variables__ = classifies individuals or items into different groups. Can be divided ito:
- ORDINAL = groups have an order or ranking i.e. class ranking in college or high school
- NOMINAL = grops are merely names, no ranking es marital status

## Study Design
- Exploratory --> Collect and analyzed data without first pre-specifying question
- Confirmatory --> Scientific method specify falsifable hypothesis, then test it --> collect data to addres single pre-specified question
- Comparative --> cntrast one quantity to others
- Non-Comparative --> estimate or predict absolute quntities 
- Observational --> arise naturally, contrast based on self-selection of units into groups. Often say subjects are exposed to a condition rether than being assigned
- Experiments --> involve manipulation or assignment --> experimenter deliberately treat differentunits in different ways. Often invole random assignment of subjects 
More data yield more information, but the manner in which that data's collected is very important.

POWER ANALYSIS = process to assess wether given study design likely to yield meaningful findings

BIAS = measuraments thata are systematicallly off-target, or sample is not representative of population of interest (observation studies are especially vulnerable to it).

## Data management (reading from coursera)
 refers to all steps of data processing that occur after the data are collected but before the actual data analysis.
 he cases represent individual units in the population of interest, although in some settings the distinction between cases and variables is not very clear.
 __Best Practices for Data Management:__
 - Name variables with brief interpretable names.
 - Short variable names convey too little meaning, and very long names are awkward to use in complex expressions
 - Variable names consisting only of letters (a-z, case sensitive), numbers (not as the first character) and the underscore character (_) will be handled easily by most statistical software.
 - Variable names consisting only of letters (a-z, case sensitive), numbers (not as the first character) and the underscore character (_) will be handled easily by most statistical software.
 - Most statistical software will treat blank, “NA”, or “.” as a missing value.

 __Spreadsheet Software__
 - Spreadsheet software can be useful for getting a quick overview of a data set, but is quite limited for more advanced data management and analysis.
- Font style and text color in a spreadsheet are generally not interpretable by statistical software so should not be used to encode important information.
- Spreadsheet graphs and charts will generally be ignored when importing spreadsheet data into statistical software.
- Each sheet in a spreadsheet workbook is usually imported as a separate dataset.
- Python can read most Excel files directly, but may struggle with large, complex, or very old files.
- Text/CSV is a better choice than spreadsheet formats (e.g. .xlsx) for data exchange and archiving.

__Databases and Other Tools__
The explosion of interest in data science and large-scale data analysis is leading to a lot of innovation and development of new tools for data management.

- Database software and tools (e.g. SQL) can be very useful for large-scale data management. Some statistical software can read data directly from a database.  Another approach is to construct a text data file from a database e.g. using SQL.
- HDF5, Apache Parquet, and Apache Arrow are open-source standards for large binary datasets.  Using these formats saves processing time relative to text/csv because fewer conversions are performed when reading and writing the data. 
- Hadoop and Spark are two popular tools for manipulating very large datasets.

__Data Files for Storage and Exchange__
Text/CSV is currently the most universal format for data exchange.

- The data in a CSV file is “delimited”, usually by a comma or a tab.
- Large data sets can be saved in compressed form (e.g. using “gzip”) and read into statistical software directly from the compressed file.  This allows the data to be read much faster, and reduces storage space.
- Some statistical software packages have proprietary binary file formats (e.g. SAS7BDAT for SAS or DTA for Stata).  These can usually be read directly into Python/Pandas but in some cases challenges arise. Formats like XML and JSON are useful for non-rectangular data but tend to produce larger files that are slower to read and process.

__Repeated Measures Data: Wide and Long__
“Repeated measures” arise when multiple measurements are made on each subject in a study.

Statistical analysis of repeated measures data is a more advanced topic, but you may encounter this type of data and need to do some basic reporting and data management with it.

Two common formats for repeated measures data are:
- Wide format: one row per subject
- Long format: one row per measurement
Python/Pandas has tools to convert between wide and long form.

__Uses of wide and long format data layouts__

- Wide format is slightly more convenient for data entry in studies where each subject is assessed the same number of times.
- Long format is more flexible, as it accommodates measures obtained at arbitrary time points; the long format is also more natural for many forms of statistical analysis, such as regression analysis.

__More Specialized Data Formats__
Other specialized data layouts exist for other types of data, e.g. data defined as graphs (networks of nodes and edges), images, geospatial data, or text data.